
Data
====
- training: pročištěný europarl, 555k vět
- dev: news11, 3k vět
- test: news13, 3k vět

- testovací data nejsou podmnožinou trénovacích

Preprocessing
=============
- europarl pročištěn od vět označených jako cs, které ale byly v jiných
  jazycích
	- s použitím langdetect a pravidel, která byla odpozorována z korpusu
- preprocessing 
	- moses skripty:
		remove-non-printing-char.perl | 
		replace-unicode-punctuation.perl |
		normalize-punctuation.perl
	- tokenizace
	- morfemizace
		- automatické dělení na morfémy, např.
			Gesetzbuch -> Gesetz@@ buch
			hlavní město Latinské -> hlav@@ ní měst@@ o Latin@@ ské
OB: technicka poznamka: '@@ ' neni stastna volba, bude se tlouct s BPE v neuronovych prekladacich
		- použita pythonovská knihovna polyglot s předtrénovanými jazykovými modely pro morfessor
		- TODO: vyzkoušet chytřejší language-specific morfemizaci
OB: a naopak take jednodussi, plne unsupervised BPE. Kolegove rikaji, ze pro nemcinu pouzivaji BPE i pro frazovy preklad a ze to dopadne lepe nez compound splitting, protoze ho to rovnou zahrnuje.
		Gesetzbuch -> gesetz ++ buch (pro němčinu)
		hlavní město -> hlav@@ @@ní měst@@ @@o (pro češtinu, "ní" jako sufix
		je něco jiného než samostatné slovo "ní")
OB: tohle by bylo zajimave promerit, ale pokusy, ktere pro mne zkousel Matiss Rikters s Neural Monkey nejak spis ukazovaly, ze to k nicemu nevede (ale mozna tam mel i bug, oznacovani pomoci @@ na druhe strane nez normalne vedlo k podstatne horsimu skore, coz je blbost)
	- TODO: změnit slovosled německých sloves:
		Ich will in dem besten Staat, der in Europa **liegt**, **wohnen**. 
			-> 
		Ich will **wohnen** in dem besten Staat, der **liegt** in Europa.
OB: toto rozhodne neni treba, seq2seq modely na poradi vstupu kaslou. t2t modely (Attention is All You Need) poradi zakodovavaji do vstupu, ale i velke vzdalenosti jsou pro ne velmi levne.

- dosud žádný truecasing (byl by potřeba velký jazykový korpus na natrénování)
ani lowercasing (přišli bychom o informace o podstatných jménech)
OB: lidi casto s NMT vubec casing neresi, ono se to vicemene nauci samo

Postprocessing po překladu
==========================
- pouze sed 's/@@ //g' (pospojování morfémů do slov)


Analýza OOV-rate
================
- europarl jako trénovací korpus vs dev

data:
#1 preprocessed, tokenized
#2 preprocessed, tokenized, morfesized
#3 + truecasing/lowercasing (TODO)

#4 

data           |  OOV_1-grams_tokens   |  Training_set_unique_1-grams
=========================================================================
#1-cs          |  7.2 %                |  183227        (100  %)
#2-cs          |  0.3 %                |  16477         (8.9  %)
bpe100-cs      |  0.0 %                |  358
bpe1000-cs     |  0.0 %                |  1256
pbe10000-cs    |  0.0 %                |  10174         
pbe15000-cs    |  0.0 %                |  15092
pbe18000-cs    |  0.0 %                |  18021
pbe20000-cs    |  0.0 %                |  19972
pbe50000-cs    |  0.3 %                |  48307
pbe100000-cs   |  0.4 %                |  55031
pbe1000000-cs  |  0.8 %                |  64913
--------------------------------------------------------
#1-de          |  6.9 %                |  191741        (100  %)
#2-de          |  0.4 %                |  18008         (9.4  %)
bpe100-de      |  0.0 %                |  493
bpe1000-de     |  0.0 %                |  1392
pbe10000-de    |  0.0 %                |  10358
pbe15000-de    |  0.0 %                |  15303
pbe18000-de    |  0.0 %                |  18261
pbe20000-de    |  0.1 %                |  20232
pbe50000-de    |  0.1 %                |  49252
pbe100000-de   |  0.1 %                |  35029
pbe1000000-de  |  0.4 %                |  112004



Zjištění: 
- OOV rate u #2 je přijatelně nízká i takto bez truecasingu/lowercasingu
OB: vysledek #2 je velmi pekny. Jeste prosim porovnat s BPE: https://github.com/rsennrich/subword-nmt

Trénování modelu
================
- použito OpenNMT-py na jedné GPU na clusteru v Saarbrückenu
- pro začátek defaultní hyperparametry

Evaluace
========
- používám skript multi-bleu z OpenNMT
- #B: baseline je frázový překlad Dana Zemana
	- kvůli porovnání jsem stáhnul jeho referenční překlad z WMT14, preprocesoval,
	  tokenizoval a evaluoval stejným způsobem jako data v mém systému
- #1: model-01/model_acc_50.69_ppl_20.13_e13.pt.cs.pred
	- model z 13. epochy prvního překladu 
	- doba trénování: asi 8 hodin

OB: pocitejte, ze to chce trenovat aspon par dni, spis tyden (ty rychlejsi implementace jako Marian, t2t; nevim, jake je OpenNMT)

	#1.1 model-03/model_acc_50.74_ppl_20.12_e34.pt
	- to samé jsem nechal dojít do 34. epochy, trénování zřejmě stagnuje,
	  výsledek je stále stejný
- #2: model-04/model_acc_50.83_ppl_20.28_e13.pt
	- defaultní model pouze s -layers 2
	- toto je maximum
	#2.1 model-04/model_acc_50.84_ppl_20.24_e21.pt
	- ukončeno v 21. epoše, výsledek stagnuje kolem 4.68

  
  
model | score
=================================================================================================
#B    | BLEU = 13.99, 47.4/19.8/9.7/4.9 (BP=0.965, ratio=0.966, hyp_len=55093, ref_len=57048)
#1    | BLEU = 4.63, 23.6/6.6/2.7/1.1 (BP=1.000, ratio=1.263, hyp_len=72079, ref_len=57048)
#2    | BLEU = 4.74, 23.9/6.8/2.8/1.1 (BP=1.000, ratio=1.257, hyp_len=71714, ref_len=57048)

#1.1  | BLEU = 4.72, 23.7/6.7/2.7/1.1 (BP=1.000, ratio=1.264, hyp_len=72100, ref_len=57048)
#2.1  | BLEU = 4.68, 23.9/6.7/2.7/1.1 (BP=1.000, ratio=1.259, hyp_len=71829, ref_len=57048)



Další pokusy s jinými hyperparametry 
------------------------------------
- trénováno na bpe7500

modelbpe1_epoch7_33.76.t7.cs.pred.post
BLEU = 2.68, 23.9/4.4/1.3/0.4 (BP=1.000, ratio=1.033, hyp_len=58953, ref_len=57048)

modelbpe2_epoch37_7.36.t7.cs.pred.post
-layer 1 -rnn_type GRU
BLEU = 0.00, 0.9/0.1/0.0/0.0 (BP=1.000, ratio=11.361, hyp_len=648124, ref_len=57048)

modelbpe4_epoch17_3.39.t7.cs.pred.post
BLEU = 3.14, 28.1/5.6/1.6/0.6 (BP=0.906, ratio=0.910, hyp_len=51920, ref_len=57048)

modelbpe4_epoch21_3.38.t7.cs.pred.post
BLEU = 3.03, 27.8/5.6/1.5/0.5 (BP=0.932, ratio=0.935, hyp_len=53312, ref_len=57048)

modelbpe3_epoch24_26.25.t7.cs.pred
BLEU = 2.93, 24.0/4.8/1.4/0.4 (BP=1.000, ratio=1.143, hyp_len=65200, ref_len=57048)



Raw opensubtitles, BPE 7500
===========================

osub-1:
-validation_metric perplexity
-max_batch_size 64
BLEU = 2.34, 29.0/5.7/1.8/0.6 (BP=0.654, ratio=0.702, hyp_len=40064,
ref_len=57048)

osub-2:
-max_batch_size 1024
-validation_metric perplexity
modelosub-2_epoch13_20.75.t7.cs.pred
BLEU = 2.34, 29.0/5.7/1.8/0.6 (BP=0.654, ratio=0.702, hyp_len=40064,
ref_len=57048)


modelosub-3_epoch13_20.75.t7
-max_batch_size 1024
-validation_metric loss
BLEU = 2.34, 29.0/5.7/1.8/0.6 (BP=0.654, ratio=0.702, hyp_len=40064,
ref_len=57048)


osub-4
-max_batch_size 1024
-layers 3
-validation_metric perplexity
modelosub-4_epoch13_20.75.t7.cs.pred
BLEU = 2.34, 29.0/5.7/1.8/0.6 (BP=0.654, ratio=0.702, hyp_len=40064,
ref_len=57048)

osub-5
-layers 3
-max_batch_size 64
-validation_metric perplexity
modelosub-5_epoch13_20.75.t7.cs.pred
BLEU = 2.34, 29.0/5.7/1.8/0.6 (BP=0.654, ratio=0.702, hyp_len=40064,
ref_len=57048)




	DATA v2
-- opensubtitles, 


bojar 13.65.37.251 -p 50018
-- train-osub-eup-50000.log
-- -layers 3 -max_batch_size 64 -validation_metric perplexity
bojar 13.65.37.251 -p 50019
bojar 13.65.37.251 -p 50020
bojar 13.65.37.251 -p 50022
bojar 13.65.37.251 -p 50024

